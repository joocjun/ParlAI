{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['ID',\n",
    "'faithfulness',\n",
    "'informativeness_step',\n",
    "'informativeness_chain',\n",
    "'faithfulness_ww',\n",
    "'repetition_word',\n",
    "'repetition_step',\n",
    "'discourse_representation',\n",
    "'coherence_step_vs_step',\n",
    "'perplexity_step',\n",
    "'perplexity_chain',\n",
    "'perplexity_step_max',\n",
    "'grammar_step',\n",
    "'grammar_step_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale = pd.read_csv(\"sup-simcse-roberta-base/scores_sampled_rationale.tsv\", sep=\"\\s+\")\n",
    "seed = pd.read_csv(\"sup-simcse-roberta-base/scores_sampled_seed.tsv\",sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>informativeness_step</th>\n",
       "      <th>informativeness_chain</th>\n",
       "      <th>faithfulness_ww</th>\n",
       "      <th>repetition_word</th>\n",
       "      <th>repetition_step</th>\n",
       "      <th>discourse_representation</th>\n",
       "      <th>coherence_step_vs_step</th>\n",
       "      <th>perplexity_step</th>\n",
       "      <th>perplexity_chain</th>\n",
       "      <th>perplexity_step_max</th>\n",
       "      <th>grammar_step</th>\n",
       "      <th>grammar_step_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.812058</td>\n",
       "      <td>0.803600</td>\n",
       "      <td>0.949626</td>\n",
       "      <td>0.954916</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.092710</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.895041</td>\n",
       "      <td>0.796667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.811216</td>\n",
       "      <td>0.782471</td>\n",
       "      <td>0.888733</td>\n",
       "      <td>0.953801</td>\n",
       "      <td>0.059904</td>\n",
       "      <td>0.115486</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.115962</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.829620</td>\n",
       "      <td>0.509421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.620849</td>\n",
       "      <td>0.628785</td>\n",
       "      <td>0.855639</td>\n",
       "      <td>0.920996</td>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.178058</td>\n",
       "      <td>0.974381</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>0.048205</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.898728</td>\n",
       "      <td>0.618685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.796608</td>\n",
       "      <td>0.754380</td>\n",
       "      <td>0.857981</td>\n",
       "      <td>0.957555</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.159927</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.980572</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.839297</td>\n",
       "      <td>0.746374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.920438</td>\n",
       "      <td>0.809401</td>\n",
       "      <td>0.930548</td>\n",
       "      <td>0.957203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992830</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.930329</td>\n",
       "      <td>0.930329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1058</td>\n",
       "      <td>0.822316</td>\n",
       "      <td>0.857469</td>\n",
       "      <td>0.913025</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.056623</td>\n",
       "      <td>0.125109</td>\n",
       "      <td>0.950460</td>\n",
       "      <td>0.997822</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.991324</td>\n",
       "      <td>0.989724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1059</td>\n",
       "      <td>0.753211</td>\n",
       "      <td>0.748647</td>\n",
       "      <td>0.902059</td>\n",
       "      <td>0.942965</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.147781</td>\n",
       "      <td>0.953762</td>\n",
       "      <td>0.998072</td>\n",
       "      <td>0.011595</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.975991</td>\n",
       "      <td>0.960290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1060</td>\n",
       "      <td>0.774088</td>\n",
       "      <td>0.781985</td>\n",
       "      <td>0.895864</td>\n",
       "      <td>0.948757</td>\n",
       "      <td>0.044925</td>\n",
       "      <td>0.097047</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.854869</td>\n",
       "      <td>0.600033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1061</td>\n",
       "      <td>0.648724</td>\n",
       "      <td>0.779499</td>\n",
       "      <td>0.871091</td>\n",
       "      <td>0.911920</td>\n",
       "      <td>0.056986</td>\n",
       "      <td>0.101742</td>\n",
       "      <td>0.868230</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.945209</td>\n",
       "      <td>0.837919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1062</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>0.709981</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.927983</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>0.134875</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.997012</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.026370</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>0.950139</td>\n",
       "      <td>0.921657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  faithfulness  informativeness_step  informativeness_chain  \\\n",
       "0        0      0.812058              0.803600               0.949626   \n",
       "1        1      0.811216              0.782471               0.888733   \n",
       "2        2      0.620849              0.628785               0.855639   \n",
       "3        3      0.796608              0.754380               0.857981   \n",
       "4        4      0.920438              0.809401               0.930548   \n",
       "...    ...           ...                   ...                    ...   \n",
       "1058  1058      0.822316              0.857469               0.913025   \n",
       "1059  1059      0.753211              0.748647               0.902059   \n",
       "1060  1060      0.774088              0.781985               0.895864   \n",
       "1061  1061      0.648724              0.779499               0.871091   \n",
       "1062  1062      0.719308              0.709981               0.864706   \n",
       "\n",
       "      faithfulness_ww  repetition_word  repetition_step  \\\n",
       "0            0.954916         0.052288         0.092710   \n",
       "1            0.953801         0.059904         0.115486   \n",
       "2            0.920996         0.070261         0.178058   \n",
       "3            0.957555         0.054255         0.159927   \n",
       "4            0.957203         1.000000         1.000000   \n",
       "...               ...              ...              ...   \n",
       "1058         0.946809         0.056623         0.125109   \n",
       "1059         0.942965         0.058786         0.147781   \n",
       "1060         0.948757         0.044925         0.097047   \n",
       "1061         0.911920         0.056986         0.101742   \n",
       "1062         0.927983         0.059045         0.134875   \n",
       "\n",
       "      discourse_representation  coherence_step_vs_step  perplexity_step  \\\n",
       "0                     0.001019                0.996038         0.008550   \n",
       "1                     0.001965                0.115962         0.008322   \n",
       "2                     0.974381                0.993593         0.020047   \n",
       "3                     0.031924                0.980572         0.006159   \n",
       "4                     0.992830                0.999375         0.008765   \n",
       "...                        ...                     ...              ...   \n",
       "1058                  0.950460                0.997822         0.014403   \n",
       "1059                  0.953762                0.998072         0.011595   \n",
       "1060                  0.003503                0.004122         0.006658   \n",
       "1061                  0.868230                0.004913         0.002365   \n",
       "1062                  0.998271                0.997012         0.020360   \n",
       "\n",
       "      perplexity_chain  perplexity_step_max  grammar_step  grammar_step_max  \n",
       "0             0.023902             0.008029      0.895041          0.796667  \n",
       "1             0.019382             0.003790      0.829620          0.509421  \n",
       "2             0.048205             0.004195      0.898728          0.618685  \n",
       "3             0.022432             0.001534      0.839297          0.746374  \n",
       "4             0.008765             0.008765      0.930329          0.930329  \n",
       "...                ...                  ...           ...               ...  \n",
       "1058          0.021803             0.010475      0.991324          0.989724  \n",
       "1059          0.023410             0.008504      0.975991          0.960290  \n",
       "1060          0.027857             0.003294      0.854869          0.600033  \n",
       "1061          0.025225             0.000284      0.945209          0.837919  \n",
       "1062          0.026370             0.017472      0.950139          0.921657  \n",
       "\n",
       "[1063 rows x 14 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale.to_json(\"all-mpnet-base-v2/scores_sampled_rationale.json\", orient=\"records\")\n",
    "seed.to_json(\"all-mpnet-base-v2/scores_sampled_seed.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>informativeness_step</th>\n",
       "      <th>informativeness_chain</th>\n",
       "      <th>faithfulness_ww</th>\n",
       "      <th>repetition_word</th>\n",
       "      <th>repetition_step</th>\n",
       "      <th>discourse_representation</th>\n",
       "      <th>coherence_step_vs_step</th>\n",
       "      <th>perplexity_step</th>\n",
       "      <th>perplexity_chain</th>\n",
       "      <th>perplexity_step_max</th>\n",
       "      <th>grammar_step</th>\n",
       "      <th>grammar_step_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1.063000e+03</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>1063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>531.000000</td>\n",
       "      <td>0.801814</td>\n",
       "      <td>0.765575</td>\n",
       "      <td>0.898153</td>\n",
       "      <td>0.947633</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>0.334976</td>\n",
       "      <td>0.497005</td>\n",
       "      <td>0.783754</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>8.724865e-03</td>\n",
       "      <td>0.865423</td>\n",
       "      <td>0.764178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>307.005972</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.059433</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.404149</td>\n",
       "      <td>0.378012</td>\n",
       "      <td>0.432950</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>9.382164e-03</td>\n",
       "      <td>0.161842</td>\n",
       "      <td>0.262597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548621</td>\n",
       "      <td>0.541855</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.880872</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.217105e-07</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>0.009932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>265.500000</td>\n",
       "      <td>0.759471</td>\n",
       "      <td>0.730439</td>\n",
       "      <td>0.872879</td>\n",
       "      <td>0.940192</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.097238</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.792387</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>3.150953e-03</td>\n",
       "      <td>0.819884</td>\n",
       "      <td>0.643639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>531.000000</td>\n",
       "      <td>0.803736</td>\n",
       "      <td>0.767908</td>\n",
       "      <td>0.903843</td>\n",
       "      <td>0.948252</td>\n",
       "      <td>0.060199</td>\n",
       "      <td>0.138296</td>\n",
       "      <td>0.522113</td>\n",
       "      <td>0.993150</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>6.400884e-03</td>\n",
       "      <td>0.925597</td>\n",
       "      <td>0.874424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>796.500000</td>\n",
       "      <td>0.850029</td>\n",
       "      <td>0.805388</td>\n",
       "      <td>0.931179</td>\n",
       "      <td>0.956290</td>\n",
       "      <td>0.091609</td>\n",
       "      <td>0.242847</td>\n",
       "      <td>0.972381</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>0.034134</td>\n",
       "      <td>1.110922e-02</td>\n",
       "      <td>0.976548</td>\n",
       "      <td>0.966701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1062.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.113630</td>\n",
       "      <td>0.113630</td>\n",
       "      <td>1.136301e-01</td>\n",
       "      <td>0.995729</td>\n",
       "      <td>0.995729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  faithfulness  informativeness_step  informativeness_chain  \\\n",
       "count  1063.000000   1063.000000           1063.000000            1063.000000   \n",
       "mean    531.000000      0.801814              0.765575               0.898153   \n",
       "std     307.005972      0.071147              0.059433               0.044653   \n",
       "min       0.000000      0.548621              0.541855               0.752552   \n",
       "25%     265.500000      0.759471              0.730439               0.872879   \n",
       "50%     531.000000      0.803736              0.767908               0.903843   \n",
       "75%     796.500000      0.850029              0.805388               0.931179   \n",
       "max    1062.000000      1.000000              1.000000               1.000000   \n",
       "\n",
       "       faithfulness_ww  repetition_word  repetition_step  \\\n",
       "count      1063.000000      1063.000000      1063.000000   \n",
       "mean          0.947633         0.284882         0.334976   \n",
       "std           0.014673         0.404149         0.378012   \n",
       "min           0.880872         0.006333         0.015124   \n",
       "25%           0.940192         0.052463         0.097238   \n",
       "50%           0.948252         0.060199         0.138296   \n",
       "75%           0.956290         0.091609         0.242847   \n",
       "max           1.000000         1.000000         1.000000   \n",
       "\n",
       "       discourse_representation  coherence_step_vs_step  perplexity_step  \\\n",
       "count               1063.000000             1063.000000      1063.000000   \n",
       "mean                   0.497005                0.783754         0.012020   \n",
       "std                    0.432950                0.366307         0.009567   \n",
       "min                    0.000194                0.000249         0.000004   \n",
       "25%                    0.016252                0.792387         0.006057   \n",
       "50%                    0.522113                0.993150         0.010422   \n",
       "75%                    0.972381                0.998695         0.015485   \n",
       "max                    0.999591                0.999876         0.113630   \n",
       "\n",
       "       perplexity_chain  perplexity_step_max  grammar_step  grammar_step_max  \n",
       "count       1063.000000         1.063000e+03   1063.000000       1063.000000  \n",
       "mean           0.025189         8.724865e-03      0.865423          0.764178  \n",
       "std            0.015631         9.382164e-03      0.161842          0.262597  \n",
       "min            0.000009         1.217105e-07      0.033936          0.009932  \n",
       "25%            0.013528         3.150953e-03      0.819884          0.643639  \n",
       "50%            0.023590         6.400884e-03      0.925597          0.874424  \n",
       "75%            0.034134         1.110922e-02      0.976548          0.966701  \n",
       "max            0.113630         1.136301e-01      0.995729          0.995729  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationale.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>informativeness_step</th>\n",
       "      <th>informativeness_chain</th>\n",
       "      <th>faithfulness_ww</th>\n",
       "      <th>repetition_word</th>\n",
       "      <th>repetition_step</th>\n",
       "      <th>discourse_representation</th>\n",
       "      <th>coherence_step_vs_step</th>\n",
       "      <th>perplexity_step</th>\n",
       "      <th>perplexity_chain</th>\n",
       "      <th>perplexity_step_max</th>\n",
       "      <th>grammar_step</th>\n",
       "      <th>grammar_step_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.807873</td>\n",
       "      <td>0.775122</td>\n",
       "      <td>0.899395</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>0.273760</td>\n",
       "      <td>0.485510</td>\n",
       "      <td>0.776327</td>\n",
       "      <td>0.019761</td>\n",
       "      <td>0.047481</td>\n",
       "      <td>1.441112e-02</td>\n",
       "      <td>0.888306</td>\n",
       "      <td>0.801281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.403892</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>0.376260</td>\n",
       "      <td>0.357267</td>\n",
       "      <td>0.428778</td>\n",
       "      <td>0.367939</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.036132</td>\n",
       "      <td>2.730905e-02</td>\n",
       "      <td>0.158496</td>\n",
       "      <td>0.231960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600881</td>\n",
       "      <td>0.638899</td>\n",
       "      <td>0.756489</td>\n",
       "      <td>0.903945</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>1.375461e-07</td>\n",
       "      <td>0.121322</td>\n",
       "      <td>0.097033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.750000</td>\n",
       "      <td>0.768905</td>\n",
       "      <td>0.748042</td>\n",
       "      <td>0.874616</td>\n",
       "      <td>0.942004</td>\n",
       "      <td>0.041616</td>\n",
       "      <td>0.067082</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.751838</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>4.168321e-03</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.734244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.810474</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>0.902760</td>\n",
       "      <td>0.950877</td>\n",
       "      <td>0.048699</td>\n",
       "      <td>0.109939</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.989932</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>8.034738e-03</td>\n",
       "      <td>0.944402</td>\n",
       "      <td>0.906839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101.250000</td>\n",
       "      <td>0.847212</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>0.932262</td>\n",
       "      <td>0.957355</td>\n",
       "      <td>0.067288</td>\n",
       "      <td>0.182834</td>\n",
       "      <td>0.964338</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.061821</td>\n",
       "      <td>1.639113e-02</td>\n",
       "      <td>0.980582</td>\n",
       "      <td>0.970663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.967468</td>\n",
       "      <td>0.888048</td>\n",
       "      <td>0.971655</td>\n",
       "      <td>0.981008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.291444</td>\n",
       "      <td>0.291444</td>\n",
       "      <td>2.914438e-01</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.994701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  faithfulness  informativeness_step  informativeness_chain  \\\n",
       "count  136.000000    136.000000            136.000000             136.000000   \n",
       "mean    67.500000      0.807873              0.775122               0.899395   \n",
       "std     39.403892      0.061591              0.050321               0.040318   \n",
       "min      0.000000      0.600881              0.638899               0.756489   \n",
       "25%     33.750000      0.768905              0.748042               0.874616   \n",
       "50%     67.500000      0.810474              0.779853               0.902760   \n",
       "75%    101.250000      0.847212              0.809182               0.932262   \n",
       "max    135.000000      0.967468              0.888048               0.971655   \n",
       "\n",
       "       faithfulness_ww  repetition_word  repetition_step  \\\n",
       "count       136.000000       136.000000       136.000000   \n",
       "mean          0.948566         0.229492         0.273760   \n",
       "std           0.014357         0.376260         0.357267   \n",
       "min           0.903945         0.011132         0.026596   \n",
       "25%           0.942004         0.041616         0.067082   \n",
       "50%           0.950877         0.048699         0.109939   \n",
       "75%           0.957355         0.067288         0.182834   \n",
       "max           0.981008         1.000000         1.000000   \n",
       "\n",
       "       discourse_representation  coherence_step_vs_step  perplexity_step  \\\n",
       "count                136.000000              136.000000       136.000000   \n",
       "mean                   0.485510                0.776327         0.019761   \n",
       "std                    0.428778                0.367939         0.026699   \n",
       "min                    0.000507                0.000817         0.000003   \n",
       "25%                    0.029444                0.751838         0.008626   \n",
       "50%                    0.413646                0.989932         0.014627   \n",
       "75%                    0.964338                0.997396         0.023199   \n",
       "max                    0.999026                0.999663         0.291444   \n",
       "\n",
       "       perplexity_chain  perplexity_step_max  grammar_step  grammar_step_max  \n",
       "count        136.000000         1.360000e+02    136.000000        136.000000  \n",
       "mean           0.047481         1.441112e-02      0.888306          0.801281  \n",
       "std            0.036132         2.730905e-02      0.158496          0.231960  \n",
       "min            0.001653         1.375461e-07      0.121322          0.097033  \n",
       "25%            0.024716         4.168321e-03      0.873900          0.734244  \n",
       "50%            0.043301         8.034738e-03      0.944402          0.906839  \n",
       "75%            0.061821         1.639113e-02      0.980582          0.970663  \n",
       "max            0.291444         2.914438e-01      0.994701          0.994701  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAajUlEQVR4nO3de2zV9f348VcBe8CtLQKW0lkd4FDnNfOCiBdUJuLidJJ5jT80TqcWEyGbijdA3WqcUTKDmDkVTVSmi5dNGQ5xQFRwkUl0U1EQJ0bbTDZarLOgfH5/GPtdBZRTznmXUx+P5ET7Oe9zzov3Gvvcp5/DKcuyLAsAgER6dPUAAMDXi/gAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkenX1AF+0cePGeO+996KioiLKysq6ehwAYCtkWRbr1q2L2tra6NHjy89tbHfx8d5770VdXV1XjwEAdMLq1atjl112+dI12118VFRURMRnw1dWVnbxNADA1mhpaYm6urr2n+NfZruLj89/1VJZWSk+AKDEbM0lEy44BQCSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAk1aurByhVt8574yvXTPz+sASTAEBpceYDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AIKm84qOhoSEOPvjgqKioiOrq6jj55JNj+fLlHdaMGjUqysrKOtwuvPDCgg4NAJSuvOJj4cKFUV9fH0uWLIl58+bFhg0b4rjjjovW1tYO684///x4//3322833XRTQYcGAEpXr3wWz507t8PXs2bNiurq6li6dGkceeSR7cd33HHHqKmpKcyEAEC3sk3XfDQ3N0dERL9+/Tocv//++2PAgAGxzz77xOTJk+Ojjz7a4nO0tbVFS0tLhxsA0H3ldebjf23cuDEuvfTSGDlyZOyzzz7tx88888zYbbfdora2Nl5++eW4/PLLY/ny5fHII49s9nkaGhpi2rRpnR0DACgxZVmWZZ154EUXXRR/+tOf4tlnn41ddtlli+ueeeaZOPbYY2PFihUxdOjQTe5va2uLtra29q9bWlqirq4umpubo7KysjOjJXHrvDe+cs3E7w9LMAkAdL2Wlpaoqqraqp/fnTrzMWHChHjiiSdi0aJFXxoeERHDhw+PiNhifORyucjlcp0ZAwAoQXnFR5Zlcckll8Sjjz4aCxYsiMGDB3/lY5YtWxYREYMGDerUgABA95JXfNTX18cDDzwQjz/+eFRUVERjY2NERFRVVUWfPn1i5cqV8cADD8QJJ5wQ/fv3j5dffjkmTpwYRx55ZOy3335F+QMAAKUlr/iYOXNmRHz2F4n9r3vuuSfOOeecKC8vj6effjqmT58era2tUVdXF+PGjYurr766YAMDAKUt71+7fJm6urpYuHDhNg0EAHRvPtsFAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBIqlOfavu1MXXqFu86dOWaiIhY8v8uSTQMAHQPznwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkFRe8dHQ0BAHH3xwVFRURHV1dZx88smxfPnyDms+/vjjqK+vj/79+8c3v/nNGDduXDQ1NRV0aACgdOUVHwsXLoz6+vpYsmRJzJs3LzZs2BDHHXdctLa2tq+ZOHFi/PGPf4yHH344Fi5cGO+9916ccsopBR8cAChNvfJZPHfu3A5fz5o1K6qrq2Pp0qVx5JFHRnNzc9x1113xwAMPxDHHHBMREffcc0/stddesWTJkjj00EMLNzkAUJK26ZqP5ubmiIjo169fREQsXbo0NmzYEKNHj25fs+eee8auu+4aixcv3uxztLW1RUtLS4cbANB9dTo+Nm7cGJdeemmMHDky9tlnn4iIaGxsjPLy8ujbt2+HtQMHDozGxsbNPk9DQ0NUVVW13+rq6jo7EgBQAjodH/X19fH3v/89Zs+evU0DTJ48OZqbm9tvq1ev3qbnAwC2b3ld8/G5CRMmxBNPPBGLFi2KXXbZpf14TU1NrF+/PtauXdvh7EdTU1PU1NRs9rlyuVzkcrnOjAEAlKC8znxkWRYTJkyIRx99NJ555pkYPHhwh/sPPPDA2GGHHWL+/Pntx5YvXx7vvPNOjBgxojATAwAlLa8zH/X19fHAAw/E448/HhUVFe3XcVRVVUWfPn2iqqoqzjvvvJg0aVL069cvKisr45JLLokRI0Z4pwsAEBF5xsfMmTMjImLUqFEdjt9zzz1xzjnnRETErbfeGj169Ihx48ZFW1tbjBkzJm6//faCDAsAlL684iPLsq9c07t375gxY0bMmDGj00MBAN2Xz3YBAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJJV3fCxatChOPPHEqK2tjbKysnjsscc63H/OOedEWVlZh9vxxx9fqHkBgBKXd3y0trbG/vvvHzNmzNjimuOPPz7ef//99tuDDz64TUMCAN1Hr3wfMHbs2Bg7duyXrsnlclFTU9PpoQCA7qso13wsWLAgqqurY4899oiLLroo1qxZU4yXAQBKUN5nPr7K8ccfH6ecckoMHjw4Vq5cGVdeeWWMHTs2Fi9eHD179txkfVtbW7S1tbV/3dLSUuiRAIDtSMHj4/TTT2//93333Tf222+/GDp0aCxYsCCOPfbYTdY3NDTEtGnTCj0GALCdKvpbbYcMGRIDBgyIFStWbPb+yZMnR3Nzc/tt9erVxR4JAOhCBT/z8UXvvvturFmzJgYNGrTZ+3O5XORyuWKPAQBsJ/KOjw8//LDDWYxVq1bFsmXLol+/ftGvX7+YNm1ajBs3LmpqamLlypVx2WWXxe677x5jxowp6OAAQGnKOz5efPHFOProo9u/njRpUkREjB8/PmbOnBkvv/xy3HvvvbF27dqora2N4447Lq6//npnNwCAiOhEfIwaNSqyLNvi/U899dQ2DQQAdG8+2wUASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJLq1dUDAACFc+u8N75yzcTvD0swyZY58wEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkvLBctvo0Ptu2/Kdz/X/7J9TpyaZBQBKgTMfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEgq7/hYtGhRnHjiiVFbWxtlZWXx2GOPdbg/y7K49tprY9CgQdGnT58YPXp0vPnmm4WaFwAocXnHR2tra+y///4xY8aMzd5/0003xa9//eu444474oUXXohvfOMbMWbMmPj444+3eVgAoPTl/cFyY8eOjbFjx272vizLYvr06XH11VfHSSedFBER9913XwwcODAee+yxOP3007dtWgCg5BX0mo9Vq1ZFY2NjjB49uv1YVVVVDB8+PBYvXrzZx7S1tUVLS0uHGwDQfRU0PhobGyMiYuDAgR2ODxw4sP2+L2poaIiqqqr2W11dXSFHAgC2M13+bpfJkydHc3Nz+2316tVdPRIAUEQFjY+ampqIiGhqaupwvKmpqf2+L8rlclFZWdnhBgB0XwWNj8GDB0dNTU3Mnz+//VhLS0u88MILMWLEiEK+FABQovJ+t8uHH34YK1asaP961apVsWzZsujXr1/suuuucemll8YNN9wQ3/nOd2Lw4MFxzTXXRG1tbZx88smFnBsAKFF5x8eLL74YRx99dPvXkyZNioiI8ePHx6xZs+Kyyy6L1tbWuOCCC2Lt2rVx+OGHx9y5c6N3796FmxoA2KxD77vtqxd9fyvWFFHe8TFq1KjIsmyL95eVlcV1110X11133TYNBgB0T13+bhcA4OtFfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAk1aurB+jOFq9cExERS+a9scU1E78/LNU4ALBdcOYDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEkVPD6mTp0aZWVlHW577rlnoV8GAChRRflsl7333juefvrp/3uRXj5CBgD4TFGqoFevXlFTU1OMpwYASlxRrvl48803o7a2NoYMGRJnnXVWvPPOO1tc29bWFi0tLR1uAED3VfD4GD58eMyaNSvmzp0bM2fOjFWrVsURRxwR69at2+z6hoaGqKqqar/V1dUVeiQAYDtS8PgYO3Zs/PjHP4799tsvxowZE3PmzIm1a9fGQw89tNn1kydPjubm5vbb6tWrCz0SALAdKfqVoH379o1hw4bFihUrNnt/LpeLXC5X7DEAgO1E0f+ejw8//DBWrlwZgwYNKvZLAQAloODx8bOf/SwWLlwYb7/9djz//PPxox/9KHr27BlnnHFGoV8KAChBBf+1y7vvvhtnnHFGrFmzJnbeeec4/PDDY8mSJbHzzjsX+qUAgBJU8PiYPXt2oZ8SAOhGfLYLAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkVfTPdilFt857IyIiDl25posnAYDux5kPACAp8QEAJPX1/bXL1KlbvMuvWwCgeJz5AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkurV1QN8HRx6321bvvO5/p/9c+rUJLMAQFdz5gMASEp8AABJiQ8AICnxAQAk9bW74PTWeW9ERMShK9d08SRfsDUXnLooFYBuwJkPACAp8QEAJCU+AICkvnbXfJQ014UA0A0ULT5mzJgRv/rVr6KxsTH233//uO222+KQQw4p1suVrMVbceHriKH9E0wCAGkUJT5+97vfxaRJk+KOO+6I4cOHx/Tp02PMmDGxfPnyqK6uLsZLdmsCBYDupCjXfNxyyy1x/vnnx7nnnhvf/e5344477ogdd9wx7r777mK8HABQQgp+5mP9+vWxdOnSmDx5cvuxHj16xOjRo2Px4sWbrG9ra4u2trb2r5ubmyMioqWlpdCjRUTEx60fRkRE6/r1RXn+rtLy+R4Wad8AKA1b8/OtGD9jP3/OLMu+cm3B4+ODDz6ITz/9NAYOHNjh+MCBA+P111/fZH1DQ0NMmzZtk+N1dXWFHu3r4cYbu3oCALZ3D/2maE+9bt26qKqq+tI1Xf5ul8mTJ8ekSZPav964cWP8+9//jv79+0dZWdk2P39LS0vU1dXF6tWro7Kycpufjy2z1+nY6zTsczr2Op1i7XWWZbFu3bqora39yrUFj48BAwZEz549o6mpqcPxpqamqKmp2WR9LpeLXC7X4Vjfvn0LPVZUVlb6hk7EXqdjr9Owz+nY63SKsddfdcbjcwW/4LS8vDwOPPDAmD9/fvuxjRs3xvz582PEiBGFfjkAoMQU5dcukyZNivHjx8dBBx0UhxxySEyfPj1aW1vj3HPPLcbLAQAlpCjxcdppp8W//vWvuPbaa6OxsTEOOOCAmDt37iYXoaaQy+ViypQpm/xqh8Kz1+nY6zTsczr2Op3tYa/Lsq15TwwAQIH4YDkAICnxAQAkJT4AgKTEBwCQVLeIjxkzZsS3v/3t6N27dwwfPjz++te/fun6hx9+OPbcc8/o3bt37LvvvjFnzpxEk5a+fPb6zjvvjCOOOCJ22mmn2GmnnWL06NFf+b8Nn8n3e/pzs2fPjrKysjj55JOLO2A3ku9er127Nurr62PQoEGRy+Vi2LBh/huylfLd6+nTp8cee+wRffr0ibq6upg4cWJ8/PHHiaYtTYsWLYoTTzwxamtro6ysLB577LGvfMyCBQvie9/7XuRyudh9991j1qxZRZ8zshI3e/bsrLy8PLv77ruzf/zjH9n555+f9e3bN2tqatrs+ueeey7r2bNndtNNN2WvvvpqdvXVV2c77LBD9sorrySevPTku9dnnnlmNmPGjOyll17KXnvtteycc87JqqqqsnfffTfx5KUl333+3KpVq7Jvfetb2RFHHJGddNJJaYYtcfnudVtbW3bQQQdlJ5xwQvbss89mq1atyhYsWJAtW7Ys8eSlJ9+9vv/++7NcLpfdf//92apVq7KnnnoqGzRoUDZx4sTEk5eWOXPmZFdddVX2yCOPZBGRPfroo1+6/q233sp23HHHbNKkSdmrr76a3XbbbVnPnj2zuXPnFnXOko+PQw45JKuvr2//+tNPP81qa2uzhoaGza4/9dRTsx/84Acdjg0fPjz76U9/WtQ5u4N89/qLPvnkk6yioiK79957izVit9CZff7kk0+yww47LPvtb3+bjR8/XnxspXz3eubMmdmQIUOy9evXpxqx28h3r+vr67Njjjmmw7FJkyZlI0eOLOqc3cnWxMdll12W7b333h2OnXbaadmYMWOKOFmWlfSvXdavXx9Lly6N0aNHtx/r0aNHjB49OhYvXrzZxyxevLjD+oiIMWPGbHE9n+nMXn/RRx99FBs2bIh+/foVa8yS19l9vu6666K6ujrOO++8FGN2C53Z6z/84Q8xYsSIqK+vj4EDB8Y+++wTv/zlL+PTTz9NNXZJ6sxeH3bYYbF06dL2X8289dZbMWfOnDjhhBOSzPx10VU/E7v8U223xQcffBCffvrpJn9z6sCBA+P111/f7GMaGxs3u76xsbFoc3YHndnrL7r88sujtrZ2k290/k9n9vnZZ5+Nu+66K5YtW5Zgwu6jM3v91ltvxTPPPBNnnXVWzJkzJ1asWBEXX3xxbNiwIaZMmZJi7JLUmb0+88wz44MPPojDDz88siyLTz75JC688MK48sorU4z8tbGln4ktLS3x3//+N/r06VOU1y3pMx+UjhtvvDFmz54djz76aPTu3burx+k21q1bF2effXbceeedMWDAgK4ep9vbuHFjVFdXx29+85s48MAD47TTTourrroq7rjjjq4erdtZsGBB/PKXv4zbb789/va3v8UjjzwSTz75ZFx//fVdPRoFUNJnPgYMGBA9e/aMpqamDsebmpqipqZms4+pqanJaz2f6cxef+7mm2+OG2+8MZ5++unYb7/9ijlmyct3n1euXBlvv/12nHjiie3HNm7cGBERvXr1iuXLl8fQoUOLO3SJ6sz39KBBg2KHHXaInj17th/ba6+9orGxMdavXx/l5eVFnblUdWavr7nmmjj77LPjJz/5SURE7LvvvtHa2hoXXHBBXHXVVdGjh//vXAhb+plYWVlZtLMeESV+5qO8vDwOPPDAmD9/fvuxjRs3xvz582PEiBGbfcyIESM6rI+ImDdv3hbX85nO7HVExE033RTXX399zJ07Nw466KAUo5a0fPd5zz33jFdeeSWWLVvWfvvhD38YRx99dCxbtizq6upSjl9SOvM9PXLkyFixYkV74EVEvPHGGzFo0CDh8SU6s9cfffTRJoHxefRlPpKsYLrsZ2JRL2dNYPbs2Vkul8tmzZqVvfrqq9kFF1yQ9e3bN2tsbMyyLMvOPvvs7Iorrmhf/9xzz2W9evXKbr755uy1117LpkyZ4q22Wynfvb7xxhuz8vLy7Pe//332/vvvt9/WrVvXVX+EkpDvPn+Rd7tsvXz3+p133skqKiqyCRMmZMuXL8+eeOKJrLq6Orvhhhu66o9QMvLd6ylTpmQVFRXZgw8+mL311lvZn//852zo0KHZqaee2lV/hJKwbt267KWXXspeeumlLCKyW265JXvppZeyf/7zn1mWZdkVV1yRnX322e3rP3+r7c9//vPstddey2bMmOGttlvrtttuy3bdddesvLw8O+SQQ7IlS5a033fUUUdl48eP77D+oYceyoYNG5aVl5dne++9d/bkk08mnrh05bPXu+22WxYRm9ymTJmSfvASk+/39P8SH/nJd6+ff/75bPjw4Vkul8uGDBmS/eIXv8g++eSTxFOXpnz2esOGDdnUqVOzoUOHZr17987q6uqyiy++OPvPf/6TfvAS8pe//GWz/939fG/Hjx+fHXXUUZs85oADDsjKy8uzIUOGZPfcc0/R5yzLMuevAIB0SvqaDwCg9IgPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApP4/OCShsbvmW40AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(rationale['repetition_word'], bins=50, density=True, alpha=0.5)\n",
    "plt.hist(seed['repetition_word'], bins=50,density=True, alpha=0.5, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "art",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
